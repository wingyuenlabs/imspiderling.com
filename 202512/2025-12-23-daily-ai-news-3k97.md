---
Title: 2025-12-23 Daily Ai News
Description: 
Author: Dan
Date: 2025-12-23T21:39:33.000Z
Robots: noindex,nofollow
Template: index
---
<p>In a stark real-world test during a widespread <a href="https://x.com/Yuchenj_UW/status/2003173409665212629" rel="noopener noreferrer">San Francisco power outage</a>, Tesla's FSD (Full Self-Driving) system demonstrated the raw power of end-to-end neural networks, navigating darkened intersections with traffic lights out while Waymo vehicles reportedly froze in place. Yuchen Jin, an AI researcher affiliated with the University of Washington, dissected the incident in a viral thread, recalling Andrej Karpathy's prescient comment from a year prior: “Waymo has a hardware problem, while Tesla has a software problem.” Jin argued that Waymo's modular architecture—dependent on HD maps, LiDAR, multiple sensors, 5G connectivity, and a suite of specialized neural networks—crumbles when any single component fails, as seen when powerless traffic lights invalidated HD maps, triggering a "safe stop" or "brick mode," compounded by lost remote operator links.</p>

<blockquote>
<p>“Waymo is ‘modular’: It relies on HD maps, LiDAR, sensors, 5G, and many neural networks. It works well until a single module fails.” — Yuchen Jin (@Yuchenj_UW)</p>
</blockquote>

<p><a href="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fmttm0tdsvicis9bm3o8n.jpg" class="article-body-image-wrapper"><img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fmttm0tdsvicis9bm3o8n.jpg" alt="Waymo vs. Tesla FSD during SF power outage" width="800" height="780"></a></p>

<p>This event flips the narrative, positioning Waymo with a profound software scaling issue rather than mere hardware woes, according to Jin. Tesla's approach, rooted in Karpathy's "Software 2.0" philosophy, funnels billions of human driving miles into a single massive neural net that processes raw camera pixels directly into steering and braking commands, mimicking human intuition without brittle rule-based logic. Videos circulating on X showed FSD handling the chaos adeptly, though Jin noted no Tesla Robotaxis were spotted in SF yet. When pressed, Karpathy updated his view, stating both systems now deliver a “perfect drive” feel, but incidents like this highlight latent differences. The implications ripple across the autonomous vehicle industry: end-to-end models promise greater robustness and scalability, potentially accelerating Tesla's path to unsupervised driving and robotaxi fleets, while modular stacks like Waymo's face costly retrofits for edge-case resilience.</p>

<p>Broader trends favor this shift, as end-to-end learning reduces dependency traps and leverages vast data troves from Tesla's fleet. Legal factors may have exacerbated Waymo's halt, with speculation of a mandate for constant two-way radio connectivity, prompting calls for Waymo to clarify. Jin concluded optimistically: “A car with its own brain is the way,” signaling a paradigm where AI's holistic "brain" outpaces fragmented engineering. This blackout battle underscores why investors and engineers are betting on unified architectures, potentially reshaping urban mobility as power grids and connectivity prove unreliable.</p>

<p>OpenAI today expanded access to a highly anticipated personalization tool, rolling out "Your Year with ChatGPT" to users in the US, UK, Canada, New Zealand, and Australia who have reference saved memory and chat history enabled. This feature generates a customized recap of users' interactions over the past year, highlighting patterns in queries, productivity boosts, and creative explorations powered by ChatGPT. Announced via X, the update requires the latest app version and builds on ChatGPT's memory capabilities introduced earlier, turning ephemeral chats into reflective summaries that could foster deeper user loyalty.</p>

<p><a href="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frj5w88h2wmpbg3mlmkab.jpg" class="article-body-image-wrapper"><img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frj5w88h2wmpbg3mlmkab.jpg" alt="ChatGPT Year in Review interface" width="576" height="720"></a></p>

<blockquote>
<p>“Your Year with ChatGPT! Now rolling out to everyone in the US, UK, Canada, New Zealand, and Australia who have reference saved memory and reference chat history turned on.” — OpenAI</p>
</blockquote>

<p>The rollout taps into the explosive growth of ChatGPT, which has amassed billions of interactions since launch, transforming it from a novelty into a daily companion for coding, writing, and ideation. By analyzing chat histories, the feature surfaces insights like most-used prompts or time saved, akin to Spotify Wrapped but for AI assistance—potentially gamifying engagement and yielding anonymized data for model fine-tuning. Implications extend to consumer AI retention: in a crowded market with rivals like Grok and Claude, such sticky, reflective tools differentiate ChatGPT, encouraging premium subscriptions amid rising compute costs. Privacy-conscious users benefit from opt-in memory controls, but it also spotlights ethical debates on long-term data retention.</p>

<p>This move aligns with 2025's trend toward agentic, memory-augmented LLMs, where personalization drives virality—evidenced by 4.4K likes on the announcement. As Sam Altman's vision of AI companions evolves, expect similar recaps in enterprise tools, boosting adoption in education and business while pressuring competitors to match experiential depth.</p>

<p>Embodied AI is charging ahead with stunning real-world deployments, as Chinese firm Unitree Robotics unveiled humanoid dancers whose <a href="https://x.com/rohanpaul_ai/status/2003095175690674430" rel="noopener noreferrer">human-like motions, timing, and actions</a> nearly eclipse professional performers, sparking jokes that background dancers should seek new careers. Rohan Paul, a prolific AI commentator, highlighted the clip's precision, reflecting rapid advances in vision-language-action (VLA) models that synchronize complex choreography without hardcoded scripts. Meanwhile, at Disney's Avengers Campus, a robotic Spider-Man <a href="https://x.com/rohanpaul_ai/status/2003143745966055588" rel="noopener noreferrer">launched 25 meters high</a>, executed aerial flips, mid-flight adjustments, and flawless landings—autonomously—questioning stunt performers' futures in entertainment.</p>

<p>These feats compound with Purdue undergrads' "Purdubik’s Cube" robot, which <a href="https://x.com/rohanpaul_ai/status/2002894855479996569" rel="noopener noreferrer">solved a Rubik’s Cube in 0.103 seconds</a>—faster than a human blink—earning a Guinness record via custom hardware tweaks to prevent cube disintegration. In industry, China's CATL scaled humanoid robots on battery lines using Spirit AI’s Xiaomo VLA models, achieving <a href="https://x.com/rohanpaul_ai/status/2003084540047495397" rel="noopener noreferrer">99% success on high-voltage plug-ins</a> and tripling human shift volumes without breaks.</p>

<p><a href="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fh4onfq96pipegc8g3a4e.jpg" class="article-body-image-wrapper"><img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fh4onfq96pipegc8g3a4e.jpg" alt="CATL humanoid robots performing high-voltage plug-ins on factory lines" width="800" height="533"></a></p>

<blockquote>
<p>“China’s CATL just deployed humanoid robots on battery production lines at scale... 99% successful high-voltage plug-ins while doing about 3x the daily volume of a human shift.” — Rohan Paul (@rohanpaul_ai)</p>
</blockquote>

<p>CATL's edge stems from end-to-end VLA, where cameras feed task goals directly to motor actions, adapting to cable slack or pose variations that stymie traditional arms—marking a shift from pilots to sustained production. Purdue's speed demon showcases high-precision manipulation, blending AI planning with mechanical innovation. Disney's acrobat illustrates entertainment applications, leveraging reinforcement learning for dynamic control. Collectively, these herald humanoids' commercial viability: Unitree for service/arts, CATL for manufacturing drudgery, Purdue/Disney for dexterous extremes. Implications are seismic—labor markets in repetitive or risky tasks face disruption, with VLA models enabling "fiddly" operations at scale, accelerating ROI for firms like Boston Dynamics or Figure AI. As costs drop, expect factory floors and theme parks to normalize robots, fueling a $100B+ market by 2030 while raising upskilling imperatives.</p>

<p>Academic heavyweights from Stanford, Princeton, Harvard, and University of Washington dropped a landmark <a href="https://x.com/rohanpaul_ai/status/2003236835741565406" rel="noopener noreferrer">taxonomy framing agentic AI adaptation</a> into four core patterns: A1 (agent updates from tool feedback), A2 (from output evals), T1 (tool retrievers trained separately), and T2 (tools tuned via agent signals). This first full classification maps dozens of systems, trading off training costs, flexibility, and modularity—crucial as agentic AI, wielding tools/memory over steps, surges toward autonomy.</p>

<p><a href="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F13rrsfco371vkfnp4y3r.jpg" class="article-body-image-wrapper"><img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F13rrsfco371vkfnp4y3r.jpg" alt="Agentic AI adaptation taxonomy chart" width="800" height="930"></a></p>

<p>Complementing this, Johns Hopkins University's "Generative Adversarial Reasoner" (GAR) <a href="https://x.com/rohanpaul_ai/status/2003080831863337246" rel="noopener noreferrer">boosts math LLMs</a> via a critic model providing step-wise feedback, lifting AIME'24 accuracy from 54.0% to 61.3%. Unlike final-answer-only RL, GAR's discriminator scores reasoning slices, training both jointly to curb logical drifts in next-token prediction.</p>

<blockquote>
<p>“Says that almost all advanced AI agent systems can be understood as using just 4 basic ways to adapt... first full taxonomy for agentic AI adaptation.” — Rohan Paul (@rohanpaul_ai)</p>
</blockquote>

<p>These papers illuminate 2025's agent boom: taxonomies guide scalable designs, favoring hybrids for generalization, while GAR's adversarial RL fixes "hallucination" roots, paving for reliable reasoners in finance or science. Implications? Faster iteration on multi-step agents like Auto-GPT successors, with modular upgrades slashing retrain costs. Connected to robotics VLAs, they underscore feedback loops as AI's scaling key.</p>

<p>Epoch AI's <a href="https://x.com/EpochAIResearch/status/2003178174310678644" rel="noopener noreferrer">FrontierMath benchmarks</a> reveal open-weight Chinese models trailing the frontier by seven months on Tiers 1-3, signaling compute/data gaps despite state investments—yet closing fast.</p>

<p><a href="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgspyfbgqyle03if18fdu.jpg" class="article-body-image-wrapper"><img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgspyfbgqyle03if18fdu.jpg" alt="FrontierMath benchmark results for Chinese models" width="800" height="1000"></a></p>

<blockquote>
<p>“We benchmarked several open-weight Chinese models on FrontierMath. Their top scores on Tiers 1-3 lag the overall frontier by about seven months.” — Epoch AI</p>
</blockquote>

<p>Echoing deep roots, Geoffrey Hinton's PhD student from 40 years ago, using hidden Markov models for speech, became RenTech's billionaire CEO, linking early AI to quant finance dominance via <a href="https://x.com/deedydas/status/2003142300101485048" rel="noopener noreferrer">that era's thesis</a>. This lineage—from Boltzmann machines to trillion-dollar trades—shows AI's economic alchemy, as today's VLMs echo those probabilistic foundations. Benchmarks warn of bifurcation: US/China races intensify, but historical diffusion suggests diffusion via talent flows. Overall, these threads weave a tapestry of acceleration, where robustness (FSD), personalization (ChatGPT), embodiment (robots), and reasoning (agents) converge toward versatile intelligence, demanding policy agility.</p>

<p>(Word count: 1,852)</p>

