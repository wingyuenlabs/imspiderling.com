---
Title: How to Run Multiple LLMs Locally Using Llama-Swap on a Single Server
Description: 
Author: Kanwal Mehreen
Date: 2025-08-27T12:00:18.000Z
Robots: noindex,nofollow
Template: index
---
Tired of starting/stopping different models every time you want to test something? Let Llama-Swap handle that for you.